{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras==2.2.5\n",
    "# !pip install tensorflow==1.13.1\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_MODEL_NAME = 'classification.h5'\n",
    "\n",
    "DATA_DIR = os.path.abspath('data')\n",
    "ALL_DIR = os.path.join(DATA_DIR, 'all')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a fair train/validation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/clean\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/clean\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/man\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/man\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/escavate\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/escavate\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def regenerate_sampling():\n",
    "    for _, dirs, _ in os.walk(ALL_DIR):\n",
    "        for d in dirs:\n",
    "            for new_dir in (TRAIN_DIR, VAL_DIR):\n",
    "                create_dir = os.path.join(new_dir, d)\n",
    "                try:\n",
    "                    os.makedirs(create_dir)\n",
    "                except FileExistsError:\n",
    "                    print(f\"recreating samples for {create_dir}\")\n",
    "                    shutil.rmtree(create_dir)\n",
    "                    os.makedirs(create_dir)\n",
    "            for _, _, files in os.walk(os.path.join(ALL_DIR, d)):\n",
    "                for file in files:\n",
    "                    if random.random() < (0.01 if d == 'clean' else 0.2):\n",
    "                        shutil.copyfile(\n",
    "                            os.path.join(ALL_DIR, d, file),\n",
    "                            os.path.join(VAL_DIR, d, file),\n",
    "                        )\n",
    "                    elif random.random() < (0.05 if d == 'clean' else 1):\n",
    "                        shutil.copyfile(\n",
    "                            os.path.join(ALL_DIR, d, file),\n",
    "                            os.path.join(TRAIN_DIR, d, file),\n",
    "                        )\n",
    "\n",
    "# regenerate_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1130 images belonging to 3 classes.\n",
      "Found 249 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From /home/paulinm/hack/junctionx/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/5\n",
      "67/70 [===========================>..] - ETA: 1s - loss: 2.1451 - acc: 0.3879"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "FROZEN_LAYERS_NUM = 100  # Magic number out of 175\n",
    "\n",
    "num_train_samples = sum([len(files) for _, _, files in os.walk(TRAIN_DIR)])\n",
    "num_valid_samples = sum([len(files) for _, _, files in os.walk(VAL_DIR)])\n",
    "\n",
    "num_train_steps = num_train_samples // BATCH_SIZE\n",
    "num_valid_steps = num_valid_samples // BATCH_SIZE\n",
    "\n",
    "gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "val_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "batches = gen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_batches = val_gen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "model = keras.applications.resnet50.ResNet50()\n",
    "# model = keras.applications.mobilenet.MobileNet() faster but much worse, .5 accuracy on validation\n",
    "\n",
    "classes = list(iter(batches.class_indices))\n",
    "model.layers.pop()\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i < FROZEN_LAYERS_NUM:\n",
    "        layer.trainable=False\n",
    "\n",
    "last = model.layers[-1].output\n",
    "x = Dense(len(classes), activation=\"softmax\")(last)\n",
    "finetuned_model = Model(model.input, x)\n",
    "finetuned_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for c in batches.class_indices:\n",
    "    classes[batches.class_indices[c]] = c\n",
    "finetuned_model.classes = classes\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "try:\n",
    "    finetuned_model.fit_generator(\n",
    "        batches,\n",
    "        steps_per_epoch=num_train_steps,\n",
    "        epochs=5,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=val_batches,\n",
    "        validation_steps=num_valid_steps,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.save(OUTPUT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = keras.models.load_model(OUTPUT_MODEL_NAME)\n",
    "finetuned_model.classes = ['clean', 'escavate', 'man']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t clean\t\tescavate\t\tman\n",
      "escavate/sc4_0661.jpg \t 0.2503759\t0.7277789\t0.021845268\n",
      "man/sc1_0046.jpg \t 0.8469689\t0.008055482\t0.14497553\n",
      "clean/sc2_0138.jpg \t 0.99945873\t0.0005194014\t2.191463e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_prediction(img_path):\n",
    "    img = image.load_img(img_path)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return finetuned_model.predict(x)\n",
    "\n",
    "print('\\t\\t\\t {}'.format(\"\\t\\t\".join(finetuned_model.classes)))\n",
    "for filename in ('escavate/sc4_0661.jpg', 'man/sc1_0046.jpg', 'clean/sc2_0138.jpg'):\n",
    "    img_path = os.path.join(VAL_DIR, filename)\n",
    "    print(filename, '\\t', '\\t'.join(map(str, make_prediction(img_path)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:15<00:00,  8.12it/s]\n",
      "100%|██████████| 101/101 [00:18<00:00,  5.42it/s]\n",
      "100%|██████████| 24/24 [00:05<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "correct_to_actual = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for _, dirs, _ in os.walk(VAL_DIR):\n",
    "    for correct_class in dirs:\n",
    "        for _, _, files in os.walk(os.path.join(VAL_DIR, correct_class)):\n",
    "            for file in tqdm(files):\n",
    "                img_path = os.path.join(VAL_DIR, correct_class, file)\n",
    "                pred = make_prediction(img_path)[0]\n",
    "                pred_class = finetuned_model.classes[np.argmax(pred)]  # can adjust argmax here\n",
    "                correct_to_actual[correct_class][pred_class] += 1\n",
    "                if correct_class != pred_class and correct_class == 'clean':\n",
    "                    print('Should be clear, but', list(zip(finetuned_model.classes, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually clean:\n",
      "{'clean': 124}\n",
      "\n",
      "Actually man:\n",
      "{'man': 69, 'clean': 32}\n",
      "\n",
      "Actually escavate:\n",
      "{'escavate': 7, 'clean': 17}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in correct_to_actual.items():\n",
    "    print(f'Actually {key}:')\n",
    "    print(dict(values))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External validation on frames from the other video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t clean\t\tescavate\t\tman\n",
      "man.jpg \t 0.0084273135\t0.0009924108\t0.99058026\n",
      "noone.jpg \t 0.9873367\t0.00852231\t0.0041410746\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\t {}'.format(\"\\t\\t\".join(finetuned_model.classes)))\n",
    "for filename in ('man.jpg', 'noone.jpg', 'escavate.jpg'):\n",
    "    img_path = os.path.join(VAL_DIR, filename)\n",
    "    print(filename, '\\t', '\\t'.join(map(str, make_prediction(img_path)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
