{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.5 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: pyyaml in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (1.17.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras==2.2.5) (1.1.0)\n",
      "Requirement already satisfied: tensorflow==1.13.1 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.33.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.24.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.17.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.3.2)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.0.8)\n",
      "Requirement already satisfied: setuptools in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.4.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (3.0.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
      "Requirement already satisfied: h5py in /home/paulinm/hack/junctionx/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.5\n",
    "!pip install tensorflow==1.13.1\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paulinm/hack/junctionx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_MODEL_NAME = 'classification.h5'\n",
    "\n",
    "DATA_DIR = os.path.abspath('data')\n",
    "ALL_DIR = os.path.join(DATA_DIR, 'all')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/clean\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/clean\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/man\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/man\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/train/escavate\n",
      "recreating samples for /home/paulinm/hack/RaspberryTrain/data/val/escavate\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def regenerate_sampling():\n",
    "    for _, dirs, _ in os.walk(ALL_DIR):\n",
    "        for d in dirs:\n",
    "            for new_dir in (TRAIN_DIR, VAL_DIR):\n",
    "                create_dir = os.path.join(new_dir, d)\n",
    "                try:\n",
    "                    os.makedirs(create_dir)\n",
    "                except FileExistsError:\n",
    "                    print(f\"recreating samples for {create_dir}\")\n",
    "                    shutil.rmtree(create_dir)\n",
    "                    os.makedirs(create_dir)\n",
    "            for _, _, files in os.walk(os.path.join(ALL_DIR, d)):\n",
    "                for file in files:\n",
    "                    if random.random() < (0.01 if d == 'clean' else 0.2):\n",
    "                        shutil.copyfile(\n",
    "                            os.path.join(ALL_DIR, d, file),\n",
    "                            os.path.join(VAL_DIR, d, file),\n",
    "                        )\n",
    "                    elif random.random() < (0.05 if d == 'clean' else 1):\n",
    "                        shutil.copyfile(\n",
    "                            os.path.join(ALL_DIR, d, file),\n",
    "                            os.path.join(TRAIN_DIR, d, file),\n",
    "                        )\n",
    "\n",
    "# regenerate_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1130 images belonging to 3 classes.\n",
      "Found 249 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From /home/paulinm/hack/junctionx/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/5\n",
      "67/70 [===========================>..] - ETA: 1s - loss: 2.1451 - acc: 0.3879"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "FROZEN_LAYERS_NUM = 100  # Magic number out of 175\n",
    "\n",
    "num_train_samples = sum([len(files) for _, _, files in os.walk(TRAIN_DIR)])\n",
    "num_valid_samples = sum([len(files) for _, _, files in os.walk(VAL_DIR)])\n",
    "\n",
    "num_train_steps = num_train_samples // BATCH_SIZE\n",
    "num_valid_steps = num_valid_samples // BATCH_SIZE\n",
    "\n",
    "gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "val_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "batches = gen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_batches = val_gen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "model = keras.applications.resnet50.ResNet50()\n",
    "# model = keras.applications.mobilenet.MobileNet() may be faster\n",
    "\n",
    "classes = list(iter(batches.class_indices))\n",
    "model.layers.pop()\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i < FROZEN_LAYERS_NUM:\n",
    "        layer.trainable=False\n",
    "\n",
    "last = model.layers[-1].output\n",
    "x = Dense(len(classes), activation=\"softmax\")(last)\n",
    "finetuned_model = Model(model.input, x)\n",
    "finetuned_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for c in batches.class_indices:\n",
    "    classes[batches.class_indices[c]] = c\n",
    "finetuned_model.classes = classes\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "try:\n",
    "    finetuned_model.fit_generator(\n",
    "        batches,\n",
    "        steps_per_epoch=num_train_steps,\n",
    "        epochs=5,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=val_batches,\n",
    "        validation_steps=num_valid_steps,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.save(OUTPUT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t clean\t\tescavate\t\tman\n",
      "escavate/sc4_0661.jpg \t 0.6940015\t0.26663688\t0.03936166\n",
      "man/sc1_0046.jpg \t 0.2460796\t0.017242521\t0.7366778\n",
      "clean/sc2_0138.jpg \t 0.99986184\t8.6562846e-05\t5.160353e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_prediction(img_path):\n",
    "    img = image.load_img(img_path)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return finetuned_model.predict(x)\n",
    "\n",
    "print('\\t\\t\\t {}'.format(\"\\t\\t\".join(finetuned_model.classes)))\n",
    "for filename in ('escavate/sc4_0661.jpg', 'man/sc1_0046.jpg', 'clean/sc2_0138.jpg'):\n",
    "    img_path = os.path.join(VAL_DIR, filename)\n",
    "    print(filename, '\\t', '\\t'.join(map(str, make_prediction(img_path)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:15<00:00,  7.81it/s]\n",
      "100%|██████████| 101/101 [00:16<00:00,  5.99it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "correct_to_actual = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for _, dirs, _ in os.walk(VAL_DIR):\n",
    "    for correct_class in dirs:\n",
    "        for _, _, files in os.walk(os.path.join(VAL_DIR, correct_class)):\n",
    "            for file in tqdm(files):\n",
    "                img_path = os.path.join(VAL_DIR, correct_class, file)\n",
    "                pred = make_prediction(img_path)[0]\n",
    "                pred_class = finetuned_model.classes[np.argmax(pred)]  # can adjust argmax here\n",
    "                correct_to_actual[correct_class][pred_class] += 1\n",
    "                if correct_class != pred_class and correct_class == 'clean':\n",
    "                    print('Should be clear, but', zip(finetuned_model.classes, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually clean:\n",
      "{'clean': 124}\n",
      "\n",
      "Actually man:\n",
      "{'man': 59, 'clean': 42}\n",
      "\n",
      "Actually escavate:\n",
      "{'clean': 21, 'escavate': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in correct_to_actual.items():\n",
    "    print(f'Actually {key}:')\n",
    "    print(dict(values))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t clean\t\tescavate\t\tman\n",
      "man.jpg \t 0.0084273135\t0.0009924108\t0.99058026\n",
      "noone.jpg \t 0.9873367\t0.00852231\t0.0041410746\n"
     ]
    }
   ],
   "source": [
    "# External predictions:\n",
    "\n",
    "print('\\t\\t\\t {}'.format(\"\\t\\t\".join(finetuned_model.classes)))\n",
    "for filename in ('man.jpg', 'noone.jpg'):\n",
    "    img_path = os.path.join(VAL_DIR, filename)\n",
    "    print(filename, '\\t', '\\t'.join(map(str, make_prediction(img_path)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
